#!/usr/bin/env python
# coding: utf-8

# <a href="https://colab.research.google.com/github/withlionbuddha/learning.ai/blob/ground/PseudoLabeling.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>

#  ğŸ˜„ ì˜ì‚¬ ë ˆì´ë¸”(Pseudo-label)
# 
# ---
# ì˜ì‚¬ ë ˆì´ë¸”ë§ì€ ì¼ë°˜ì ìœ¼ë¡œ ë ˆì´ë¸”ì´ ì¼ë¶€ë§Œ ì£¼ì–´ì¡Œì„ ë•Œ, ë‚˜ë¨¸ì§€ ë°ì´í„°ë¥¼ ì˜ˆì¸¡í•˜ì—¬ ì„±ëŠ¥ì„ ê°œì„ í•˜ëŠ”ë° ì‚¬ìš©ë©ë‹ˆë‹¤
# 
# 

# In[2]:


import numpy as np
import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.datasets import mnist


# In[ ]:


import os
import shutil
# MNIST ë°ì´í„°ì…‹ì´ ì €ì¥ëœ ê²½ë¡œ
cache_dir = os.path.expanduser('~/.keras/datasets/mnist.npz')

# ìºì‹œ íŒŒì¼ ì‚­ì œ
if os.path.exists(cache_dir):
    os.remove(cache_dir)
    print("Cached MNIST data deleted.")


# ğŸ“š ë°ì´í„°ì…‹ ë¶ˆëŸ¬ì˜¤ê¸°
# 
# ---
# 
# * mnistì€ ì†ìœ¼ë¡œ ì“´ ìˆ«ì(0-9) ì´ë¯¸ì§€ë¥¼ ëª¨ì•„ë‘” ë°ì´í„°ì…‹
# * train_inputì€ ì…ë ¥ìš© í›ˆë ¨ì´ë¯¸ì§€ë°ì´í„°
# * train_labelì€ train_inputì˜ ì •ë‹µ ë°ì´í„°
# * test_inputì€ ì…ë ¥ìš© ì‹œí—˜ì´ë¯¸ì§€ë°ì´í„°
# * test_labelì€ test_inputì˜ ì •ë‹µ ë°ì´í„°
# * train_input, test_inputì€ 0~255 ì‚¬ì´ì˜ ì •ìˆ˜ ê°’(í”½ì…€ ê°’)ìœ¼ë¡œ ì´ë£¨ì–´ì§„ ë°°ì—´

# In[ ]:


# MNIST ë°ì´í„°ì…‹ ë¶ˆëŸ¬ì˜¤ê¸°
(train_input, train_label), (test_input, test_label) = mnist.load_data()


# In[ ]:


print(f"train_input shape: {train_input.shape}")
print(f"axis=0 (batch of images): {train_input.shape[0]}")
print(f"axis=1 (height of each image): {train_input.shape[1]}")
print(f"axis=2 (width of each image): {train_input.shape[2]}")
print(f"train_label shape: {train_label.shape}")

print(f"-----------------------------------")
print(f"test_input shape: {test_input.shape}")
print(f"test_label shape: {test_label.shape}")


# ğŸ“š ë°ì´í„° ì „ì²˜ë¦¬
# 
# 
# 
# ---
# 
# 
# 
# *  ì´ë¯¸ì§€ ë°ì´í„° í˜•íƒœì˜ ì¼ê´€ì„±ì„ ìœ„í•´ì„œ channel demensionì„ ì¶”ê°€í•œë‹¤.
# *  ì…ë ¥ê°’(train_expand_input, test_input)ì€ astype("float32")ë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ë¥¼ 32ë¹„íŠ¸ ë¶€ë™ ì†Œìˆ˜ì  í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤. ì´ëŠ” ì‹ ê²½ë§ ëª¨ë¸ì´ ì‹¤ìˆ˜ ê°’ì„ ì²˜ë¦¬í•˜ëŠ” ë° ë” ì í•©í•˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.
# * ì…ë ¥(train_expand_input, test_input) ë°ì´í„°ì˜ ê° ì´ë¯¸ì§€ì˜ í”½ì…€ ê°’(0~255)ì„ 255.0ìœ¼ë¡œ ë‚˜ëˆ ì„œ 0ê³¼ 1 ì‚¬ì´ì˜ ê°’ìœ¼ë¡œ ìŠ¤ì¼€ì¼ë§í•©ë‹ˆë‹¤.
# 
# 
# 

# In[ ]:


# ë°ì´í„° ì „ì²˜ë¦¬
train_expand_input = np.expand_dims(train_input, axis=-1)
test_expand_input = np.expand_dims(test_input, axis=-1)
print(f"train_expand_input shape: {train_expand_input.shape}")

train_expand_input = train_expand_input.astype("float32") / 255.0
test_expand_input = test_expand_input.astype("float32") / 255.0


# ğŸ“š ë°ì´í„° íƒ€ì… í™•ì¸
# 
# 
# 
# ---
# 
# 
# * numpy.ndarray ëŠ” NumPy ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ ë‹¤ì°¨ì› ë°°ì—´ ê°ì²´ë¡œ, íš¨ìœ¨ì ì¸ ìˆ˜ì¹˜ ì—°ì‚°

# In[ ]:


type(train_expand_input)


# ğŸ“š ë°ì´í„° ë¶„í•  , ë°ì´í„° ìŠ¬ë¼ì´ì‹±
# 
# 
# 
# ---
# 
# 
# *   train_expand_input[:num_labeled]ì€ ì…ë ¥ìš© í›ˆë ¨ë°ì´í„°(train_expand_input)ì˜ 6000ê°œ images ì¤‘ì—ì„œ 1000ê°œì˜ imagesë¥¼ ë¶„í• í•˜ì—¬ input_labeledì— í• ë‹¹í•©ë‹ˆë‹¤.
# 
# 

# In[ ]:


# ë ˆì´ë¸”ì´ ìˆëŠ” ë°ì´í„°ë¥¼ ì¼ë¶€ë§Œ ì‚¬ìš©í•˜ê³  ë‚˜ë¨¸ì§€ëŠ” ì˜ì‚¬ ë ˆì´ë¸”ë¡œ ì²˜ë¦¬
# ì—¬ê¸°ì„œëŠ” ì˜ˆì‹œë¡œ train_labelì˜ ì•ë¶€ë¶„ë§Œ ì‚¬ìš©
num_labeled = 1000
train_input_labeled = train_expand_input[:num_labeled]
train_label_labeled = train_label[:num_labeled]


# input_labeledì˜ í˜•íƒœëŠ”

# In[ ]:


print(f"train_input_labeled shape: {train_input_labeled.shape}")
print(f"train_label_labeled shape: {train_label_labeled.shape}")


# In[ ]:


test_input_unlabeled = test_expand_input[num_labeled:]
test_label_unlabeled = test_label[num_labeled:]  # test_label_unlabedëŠ” ì‹¤ì œ í•™ìŠµì— ì‚¬ìš©ë˜ì§€ ì•ŠìŒ

print(f"test_input_unlabeled shape: {test_input_unlabeled.shape}")
print(f"test_label_unlabeled shape: {test_label_unlabeled.shape}")


# In[ ]:


# ê°„ë‹¨í•œ ëª¨ë¸ êµ¬ì„±
model = models.Sequential([
    layers.Flatten(input_shape=(28, 28)),
    layers.Dense(128, activation='relu'),
    layers.Dense(10, activation='softmax')
])


# In[ ]:


model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])


# In[ ]:


# ë¨¼ì € ë¼ë²¨ì´ ìˆëŠ” ë°ì´í„°ë¡œ í•™ìŠµ
model.fit(train_input_labeled , train_label_labeled , epochs=5, batch_size=32, validation_split=0.2)


# ğŸ“š ì˜ì‚¬ ë ˆì´ë¸” ìƒì„±
# 
# ì˜ì‚¬ ë ˆì´ë¸”ì€ ì˜ˆì¸¡ëœ ê²°ê³¼ë¡œ ìƒˆë¡œ ìƒì„±ëœ ë¶„ë¥˜ì˜ ì¸ë±ìŠ¤ ì…ë‹ˆë‹¤.
# 
# ---
# 
# *   predict()í•¨ìˆ˜ì—ì„œ ì…ë ¥ìš© ì‹œí—˜ë°ì´í„°(test_input_unlabeled)ì— ëŒ€í•´ì„œ  ê° ìˆ«ì(0~9) ë³„ë¡œ ì˜ˆì¸¡ëœ í™•ìœ¨ê°’ì„ ê²°ê³¼ê°’ìœ¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
# 
# *   np.argmax() í•¨ìˆ˜ì—ì„œ ì˜ˆì¸¡ëœ í™•ìœ¨ê²°ê³¼ê°’ ì¤‘ì—ì„œ ê°€ì¥ ë†’ì€ í™•ìœ¨ê°’ì˜ ì¸ë±ìŠ¤ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
# 
# 
# 
# 
# 
# 
# 
# 

# In[ ]:


predicted = model.predict(test_input_unlabeled)


# In[ ]:


print(f"predicted.shape : {predicted.shape}" )
print(f"len(predicted) : {len(predicted)}")
print(f"predicted[0] : {predicted[0]}")
print(f"predicted[1] : {predicted[1]}")
print(f"predicted[2] : {predicted[2]}")


# In[ ]:


# ì˜ì‚¬ ë ˆì´ë¸” ìƒì„±: ë ˆì´ë¸”ì´ ì—†ëŠ” ë°ì´í„°ë¥¼ ëª¨ë¸ì„ í†µí•´ ì˜ˆì¸¡
pseudo_labels = np.argmax(predicted, axis=1)
pseudo_labels


# In[ ]:


len(pseudo_labels)


# In[ ]:


# ë¼ë²¨ì´ ì—†ëŠ” ë°ì´í„°ì— ëŒ€í•´ ì˜ˆì¸¡ëœ ì˜ì‚¬ ë ˆì´ë¸”ë¡œ ë‹¤ì‹œ í•™ìŠµ
x_combined = np.concatenate([train_input_labeled, test_input_unlabeled ])
y_combined = np.concatenate([train_label_labeled, pseudo_labels])


# In[ ]:


model.fit(x_combined, y_combined, epochs=5, batch_size=32, validation_split=0.2)

# í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ì„±ëŠ¥ í™•ì¸
test_loss, test_acc = model.evaluate(train_input_labeled, train_label_labeled)
print(f"Test accuracy: {test_acc:.4f}")

